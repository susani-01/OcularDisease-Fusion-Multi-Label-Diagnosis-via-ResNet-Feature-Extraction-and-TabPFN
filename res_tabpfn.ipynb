{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3236ad6-1a9f-453e-839b-7f4bd19b205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f8b94-c7f6-4b8e-a66e-91e66223f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained ResNet18 & remove classification head\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove last layer\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67be34-0f9d-400a-8754-74f465553434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set device \n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained ResNet18 & remove classification head\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove last layer\n",
    "model.eval()\n",
    "\n",
    "# Define transformation (ResNet format)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#  extract image features\n",
    "def extract_features(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = transform(img).unsqueeze(0).to(device)  # Convert to tensor\n",
    "    with torch.no_grad():\n",
    "        features = model(img).squeeze().cpu().numpy()  # Extract features\n",
    "    return features\n",
    "\n",
    "# Process all images\n",
    "image_dir = \"/Users/tony/Documents/research_projects/rest_net_tab/ocular/tab_rest/processed_images\"\n",
    "image_features = {}\n",
    "\n",
    "for img_name in os.listdir(image_dir):\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_features[img_name] = extract_features(img_path)\n",
    "\n",
    "# Convert to DataFrame & save for future use\n",
    "image_features_df = pd.DataFrame.from_dict(image_features, orient='index')\n",
    "image_features_df.index.name = 'image_id'\n",
    "image_features_df.to_csv(\"/Users/tony/Documents/research_projects/rest_net_tab/ocular/tab_rest/image_feature.csv\")\n",
    "\n",
    "print(\" Image feature extraction complete! Saved as 'image_features.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c4118-4d69-43f0-9aff-4b890a228b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9128cd3-dd1b-4b6e-be93-547a1e16a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the metadata and merge with Images features\n",
    "import pandas as pd\n",
    "# Load metadata CSV\n",
    "metadata = pd.read_csv('/Users/tony/Documents/research_projects/rest_net_tab/ocular/tab_rest/full_df.csv')\n",
    "\n",
    "# Extract filenames from both Left and Right Fundus columns\n",
    "metadata = metadata.melt(\n",
    "    id_vars=[\"ID\", \"Patient Age\", \"Patient Sex\", \"Left-Diagnostic Keywords\", \"Right-Diagnostic Keywords\",\n",
    "             \"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\", \"filepath\", \"labels\", \"target\", \"filename\"],\n",
    "    value_vars=[\"Left-Fundus\", \"Right-Fundus\"],\n",
    "    var_name=\"Eye\",\n",
    "    value_name=\"image_id\"\n",
    ")\n",
    "\n",
    "# Ensure filenames match those in image_features.csv\n",
    "metadata[\"image_id\"] = metadata[\"image_id\"].astype(str)\n",
    "\n",
    "# Load extracted image features\n",
    "image_features = pd.read_csv(\"/Users/tony/Documents/research_projects/rest_net_tab/ocular/tab_rest/image_feature.csv\")\n",
    "\n",
    "\n",
    "# Merge datasets based on image_id\n",
    "df = metadata.merge(image_features, on=\"image_id\", how=\"left\")  # Use 'left' join to keep all metadata rows\n",
    "\n",
    "# Drop unnecessary columns if needed\n",
    "df.drop(columns=[\"filepath\"], inplace=True)\n",
    "\n",
    "# Display merged dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4923e-d07a-4c11-973b-15c744028057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how = 'all',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415d3e2-de41-419e-97b0-835dce0ec9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feature_rows = df[df.iloc[:, -512:].isnull().any(axis=1)]\n",
    "print(\"Rows with missing features:\", len(missing_feature_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabc976-d71b-47a0-850f-099befbf1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_images = missing_feature_rows[\"image_id\"].unique()\n",
    "print(\"Missing images:\", missing_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0a6c2-613b-468f-95aa-6a98bc7eefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(include=['number']).mean()\n",
    "proc_data = df.fillna(num,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b779d-e47d-4f38-9277-8ea451d8bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae68e6-6c24-4050-89e0-1bb825402d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[''].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80921c-5f60-4cfb-b569-9310a28dd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "# Features: Metadata + Image features\n",
    "feature_columns = ['Patient Age', 'Patient Sex'] + [str(i) for i in range(512)]  # Adjust for your ResNet features\n",
    "X = df[feature_columns]\n",
    "\n",
    "# Encode 'Patient Sex' (e.g., M=0, F=1)\n",
    "X['Patient Sex'] = X['Patient Sex'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Targets: All diagnostic labels\n",
    "target_columns = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "y = df[target_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c16703-8960-4087-b81b-b743fa4289c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df.drop(columns=['ID', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords', \n",
    "                  'filename', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bee96e-508c-46c3-be1c-29484410469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding of categorical dataset\n",
    "dfa['Patient Sex'] = df['Patient Sex'].map({'Male':0,'Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d74dd5-b97b-4840-8bf3-aed62027b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['target'] = df['target'].apply(lambda x: np.argmax(eval(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7f8a5-61a3-41e4-ac9d-97da279069d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.select_dtypes(include=['object']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5530ad-7f59-4597-8dda-7e0a2add7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove of columns which are not going to be used in training\n",
    "dfa.drop(columns = ['N','D','G','C','A','H','M','O','Eye','image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227144e-57e3-4e2d-8021-e0817d5caa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.drop(columns=['Eye','image_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08d102-b575-4f5d-b27f-8276c2a5698c",
   "metadata": {},
   "source": [
    "# further processing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc521a0-22e7-4444-b66e-cb30c842f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = dfa.drop(columns=['target','Patient Age','Patient Sex'])\n",
    "scaler = StandardScaler()\n",
    "scaled_features =scaler.fit_transform(features)\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_features,columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8fcaa-8f84-43b1-ac9f-243dc1ca4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce the dataset to 100 principal components\n",
    "pca = PCA(n_components=98)  # Adjust based on the dataset\n",
    "X_pca = pca.fit_transform(scaled_df)\n",
    "\n",
    "# Convert PCA output to DataFrame\n",
    "X_pca_df = pd.DataFrame(X_pca, columns=[f\"PCA_{i}\" for i in range(98)])\n",
    "\n",
    "# Check how much variance is retained\n",
    "explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"Explained Variance: {explained_variance:.4f}\")  # Should be high (e.g., >90%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36877083-c839-4af3-bbb1-6f13a3d318fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the target column back\n",
    "X_pca_df[\"target\"] = dfa[\"target\"]\n",
    "X_pca_df[\"Patient Age\"] = dfa[\"Patient Age\"]\n",
    "X_pca_df[\"Patient Sex\"] = dfa[\"Patient Sex\"]\n",
    "dfe = X_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f060d-0cad-410f-bcd1-b7fab5fdc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE(sampling_strategy=\"auto\",random_state=42)\n",
    "# x_train_s,y_train_s = smote.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717ff47-8f8e-4522-98dc-49ef40cd8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "X = dfe.drop(columns=[\"target\"])\n",
    "y = dfe[\"target\"]\n",
    "\n",
    "#train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=1000,stratify = y,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269dd6e4-2ca0-487f-9ec9-2d899385d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Train Tabpfn model\n",
    "tabr = TabPFNClassifier(device=\"cpu\",ignore_pretraining_limits=True)\n",
    "tabr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d9951-259b-4c4c-975d-668334ef2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "pred = tabr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "print(\"Accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15b422-adbb-4f88-86e0-417225f3a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred)\n",
    "plt.title(\"Hybrid Model Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6317a-2bc9-4fdb-8829-8dd0071486c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "classifier = MultiOutputClassifier(TabPFNClassifier(device='cpu'))\n",
    "classifier.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "# Evaluate (example: F1-score per class)\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "for i, col in enumerate(target_columns):\n",
    "    print(f\"F1 for {col}: {f1_score(y_test.iloc[:, i], y_pred[:, i])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
